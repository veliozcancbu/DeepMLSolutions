{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\"\"\"\n",
    "Write a Python function that performs linear regression using gradient descent. The function should take NumPy arrays X (features with a column of ones for the intercept) and y (target) as input, along with learning rate alpha and the number of iterations, and return the coefficients of the linear regression model as a NumPy array. Round your answer to four decimal places. -0.0 is a valid result for rounding a very small number.\n",
    "\n",
    "Example:\n",
    "Input:\n",
    "X = np.array([[1, 1], [1, 2], [1, 3]]), y = np.array([1, 2, 3]), alpha = 0.01, iterations = 1000\n",
    "Output:\n",
    "np.array([0.1107, 0.9513])\n",
    "Reasoning:\n",
    "The linear model is y = 0.0 + 1.0*x, which fits the input data after gradient descent optimization.\n",
    "\"\"\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T16:00:02.555461Z",
     "start_time": "2025-10-25T16:00:02.552249Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# NumPy\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def linear_regression_gradient_descent(X: np.ndarray, y: np.ndarray, alpha: float, iterations: int) -> np.ndarray:\n",
    "    m, n = X.shape\n",
    "    theta = np.zeros(n)\n",
    "\n",
    "    for _ in range(iterations):\n",
    "        y_pred = X @ theta\n",
    "        gradient = (1 / m) * (X.T @ (y_pred - y))\n",
    "        theta -= alpha * gradient\n",
    "\n",
    "    return np.round(theta, 4)"
   ],
   "id": "50a8b5565a860c3f",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T16:00:02.870481Z",
     "start_time": "2025-10-25T16:00:02.861881Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X = np.array([[1, 1], [1, 2], [1, 3]])\n",
    "y = np.array([1, 2, 3])\n",
    "alpha = 0.01\n",
    "iterations = 1000\n",
    "print(linear_regression_gradient_descent(X, y, alpha, iterations))"
   ],
   "id": "b064adb1e2e99455",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1107 0.9513]\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T16:00:03.320063Z",
     "start_time": "2025-10-25T16:00:03.316930Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# PyTorch\n",
    "\n",
    "import torch\n",
    "\n",
    "def linear_regression_gradient_descent_t(X, y, alpha, iterations) -> torch.Tensor:\n",
    "    X_t = torch.as_tensor(X, dtype=torch.float)\n",
    "    y_t = torch.as_tensor(y, dtype=torch.float).reshape(-1, 1)\n",
    "    m, n = X_t.shape\n",
    "    theta = torch.zeros((n, 1), dtype=torch.float, requires_grad=True)\n",
    "\n",
    "    for _ in range(iterations):\n",
    "        y_pred = X_t @ theta\n",
    "        loss = torch.mean((y_pred - y_t) ** 2)\n",
    "        loss.backward()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            theta -= alpha * theta.grad\n",
    "\n",
    "        theta.grad.zero_()\n",
    "\n",
    "    theta = torch.round(theta.flatten() * 10000) / 10000\n",
    "\n",
    "    return theta"
   ],
   "id": "d96ba034a4e009cd",
   "outputs": [],
   "execution_count": 10
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
